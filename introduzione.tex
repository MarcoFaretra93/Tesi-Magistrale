Negli ultimi tempi, la mole di dati all'interno delle aziende cresce quotidianamente, per questo motivo molte compagnie desiderano mantenere i propri dati in knowledge graph, che per l'utilizzo e la gestione si necessita di un Knowledge Graph Management System (KGMS). 
Un KGMS completo deve svolgere compiti complessi di reasoning, ed allo stesso tempo ottenere performance efficienti e scalabili sui Big Data con una complessit\`a computazionale accettabile. Inoltre necessita di interfacce con i database aziendali, il web e il machine learning. 
Fin dagli anni 70, l'importanza della conoscenza \`e stata evidente, e l'idea di salvare conoscenza e di elaborarla per trarre nuova conoscenza esisteva gi\`a da allora. Il collo di bottiglia era la tecnologia di quei tempi, gli hardware erano troppo lenti, la memoria principale troppo piccola; i DBMS erano troppo lenti e rigidi; Non era presente un web dove un sistema esperto poteva acquisire dati; il machine learning e le reti neurali furono ridicolizzate e non riuscite.
Con il passare degli anni, l'avvento tecnologico ha subito una crescita radicale, l'hardware si \`e evoluto, le tecnologie dei database sono migliorate notevolmente, \`e presente un web con dati aperti, le aziende possono partecipare sui social networks. La ricerca ha portato ad una comprensione migliore di molti aspetti nell'elaborazione della conoscenza e reasoning su grandi quantit\`a di dati.
A causa di tutto ci\`o, migliaia di grandi e medie aziende, desiderano gestire i propri knowledge graph e cercano adeguati KGMS. Inizialmente soltanto le grandi aziende ad esempio Google (che utilizza il proprio knowledge graph per il proprio motore di ricerca), Amazon, Facebook, ecc... ne possedevano uno, ma con il passare degli anni molte aziende medio/basse desiderano avere un knowledge graph aziendale privato, che contiene molti dati in forma di fatti, come ad esempio conoscenza su clienti, prodotti, prezzi, concorrenti, piuttosto che conoscenza di tutto il mondo da Wikipedia o altre fonti simili.  


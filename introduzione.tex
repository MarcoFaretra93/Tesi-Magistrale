Nell'ultimo decennio, piccole, medie e grandi aziende si trovano sempre più di fronte alla sfida di dover produrre, trattare ed utilizzare una quantità sempre maggiore di dati. Ciò è dovuto principalmente alla diffusione di strumenti tecnologici, all'aumento della capacità di calcolo, allo sviluppo di Internet, dei sensori e delle reti di comunicazione. \newline
Tale crescita porta ad una proliferazione delle sorgenti dei dati disponibili, con un conseguente incremento delle mole di dati da gestire e potenzialmente utilizzare per fini operativi e decisionali. Questo fenomeno, spesso conosciuto come Big Data, ha introdotto diversi problemi: i tempi di risposta sono aumentati drasticamente; la memoria centrale è insufficiente a contenere i dati necessari alle elaborazioni; lo spazio di storage e l'hardware cominciano a non essere più sufficienti. \newline
L'importanza della conoscenza è stata evidente fin dagli anni '70 e il suo utilizzo si è presto diffuso in molti ambiti industriali e tecnici, tra cui il supporto alle decisioni e il data warehousing. \newline
Al giorno d'oggi, l'avvento dei Big Data, ha reso ancora più essenziale elaborare e trattare tale conoscenza, cogliendo la sfida di sfruttarla in attività complesse, spesso producendone di nuova (\emph{reasoning}). \newline
In effetti, il termine attuale "economia della conoscenza"~\cite{WIKI:CONOSCENZA} indica proprio l'insieme delle attività umane volte a trarre valore, tangibile e intangibile, da tale conoscenza. La conoscenza, e quindi l'informazione che la costituisce, è sempre più vista come forza motrice nelle attività di business. Ci sono molte aziende di consulenza informatica e di business la cui azione è centrata sulla conoscenza: ad esempio start-up che vendono dati estratti dal web; banche che vendono e utilizzano i dati per sofisticate inferenze relative ai propri clienti, con vari fini tra cui: profilazione, mantenimento della clientela, sviluppo di sistemi di recommendation, contrasto alle frodi, vendita dei dati a terze parti e molto altro. \newline
La forte crescita di interesse verso la conoscenza è avvenuta negli ultimi anni. In passato erano presenti diverse difficoltà, sia tecniche che teoriche, i linguaggi di programmazione erano molto complessi e gli ingegneri erano in numero limitato, l'hardware, i database, erano inadeguati e rappresentavano un collo di bottiglia per grandi elaborazioni. \newline
Con il passare degli anni, l'avvento tecnologico ha subito una crescita esponenziale, l'hardware si è evoluto, le tecnologie dei database sono migliorate notevolmente, i linguaggi di programmazione sono diventati molto più semplici, sono nati nuovi paradigmi di programmazione, inoltre è possibile utilizzare framework architetturali che fungono da middleware e permettono quindi la riduzione di scrittura di codice da parte dello sviluppatore. Ovviamente questa semplificazione ha portato ad un enorme vantaggio nell'elaborazione di conoscenza e reasoning su grandi quantità di dati. \newline
Il termine \emph{Knowledge Graph} è stato originariamente riferito solo a quello di Google, ovvero "una base di conoscenze utilizzata da Google per migliorare i risultati di ricerca del suo motore, con informazioni di ricerca semantica raccolte da una grande varietà di fonti". Nel frattempo, altri colossi come Facebook, Amazon, ecc., hanno costruito i proprio Knowledge Graph e molte altre aziende mostrano di voler mantenere un knowledge graph privato aziendale che contiene grandi quantità di dati. Tale Knowledge Graph aziendale dovrebbe contenere conoscenze di business rilevanti, ad esempio su clienti, prodotti, prezzi, ecc. Questo dovrebbe essere gestito da un Knowledge Graph Management System (KGMS), cioè un sistema di gestione delle basi di conoscenza in grado di svolgere task su grandi quantità di dati fornendo strumenti per il \emph{data analytics e il machine learning}. La parola '\textit{graph}' in questo contesto viene spesso fraintesa: molti credono che avere un Graph Database System (Database a grafo) e alimentare tale database con i dati, sia sufficiente per ottenere un Knowledge Graph aziendale, altri pensano erroneamente che i knowledge graphs siano limitati alla memorizzazione e all'analisi dei dati di grafi~\cite{bellomarini2017swift}. \newline
Come definito in~\cite{bellomarini2017swift} poniamo ora attenzione ai requisiti di un KGMS completo. Esso deve svolgere compiti complessi di reasoning, ed allo stesso tempo ottenere performance efficienti e scalabili sui Big Data con una complessit\`a computazionale accettabile. Inoltre necessita di interfacce con i database aziendali, il web e librerie per il machine learning. Il core di un KGMS deve fornire un linguaggio per rappresentare la conoscenza e permettere il reasoning.\newline \newline
Questa tesi descrive il contributo allo sviluppo di un sistema che soddisfa tutti i requisiti del KGMS, ed utilizza un linguaggio che fa parte della famiglia del Datalog. \newline
Datalog è un linguaggio di interrogazione per basi di dati che ha riscosso un notevole interesse dalla metà degli anni ottanta. È un linguaggio affine al Prolog, utilizzato nell'ambito dei database relazionali. In un certo senso è un sottoinsieme di Prolog poiché, nella sua versione base, Datalog è basato su regole di deduzione che non permettono l'utilizzo di simboli di funzione e non adotta di un modello di valutazione~\cite{atzeni2006basi} . \newline
Ogni regola è composta da una \emph{testa} (chiamata anche head o conseguente) e da un \emph{corpo} (chiamato anche body o antecedente) a loro volta formati da uno o più predicati atomici (o semplicemente \emph{atomi}). Se tutti gli atomi del corpo sono verificati, ne consegue che anche il predicato atomico della testa lo sia. L'espressività di Datalog è dovuta alla possibilità di scrivere regole ricorsive, cioè in grado di richiamare il medesimo atomo della testa anche nel corpo della regola. \newline
Datalog si è affermato come uno dei migliori linguaggi per il reasoning basato sulla conoscenza. Durante gli anni è stato studiato in dettaglio, nel data exchange e nella data integration~\cite{furche2016data}. \newline
Tuttavia Datalog ha un limitato potere espressivo, a causa dell'assenza di quantificazione esistenziale. È quindi stata progettata una famiglia di linguaggi, chiamata Datalog$^\pm$, che aggiunge maggiore potenza espressiva al linguaggio nativo~\cite{bellomarini2017swift}. \newline 
In particolare la famiglia Datalog$^\pm$ estende Datalog con quantificatori esistenziali nelle teste delle regole, ed allo stesso tempo limita la sua sintassi in modo da ottenere decidibilità e scalabilità dei dati~\cite{cali2013taming,cali2012towards,cali2010datalog+}.  \newline \newline
Il sistema che presentiamo ed utilizziamo in questa tesi, Vadalog Reasoner, è il contributo dell'università di Oxford al progetto VADA~\cite{VADA}, in collaborazione con le università di Edimburgo e Manchester. La mia attività è stata svolta presso il Laboratorio basi di dati del Dipartimento di Ingegneria dell'Università Roma Tre, lavorando da remoto con il mio correlatore Luigi Bellomarini. \newline
Il \emph{Vadalog Reasoner} è un KGMS, che offre un motore centrale di reasoning principale ed un linguaggio, il \emph{Vadalog}, per la gestione e l'utilizzo. \newline
Vadalog appartiene alla famiglia Datalog$^\pm$ sopra descritta ed è in grado di soddisfare tutti i requisiti di un KGMS completo sopra definiti. \newline
Il core logico del Vadalog Reasoner è in grado di processare tale linguaggio, è in grado di eseguire task di reasoning ontologici e risulta computazionalmente efficiente, tale da soddisfare i requisiti citati. \newline
Il problema principale nell'utilizzo del Datalog$^\pm$ è che l'introduzione della quantificazione esistenziale nelle teste rende il linguaggio indecidibile. Sono quindi nati una serie di frammenti (cioè delle restrizioni) di Datalog$^\pm$ che hanno l'obiettivo minimo di garantire la decidibilità. Tali frammenti hanno diversa complessità computazionale, esponenziale nel caso più generale. \newline
Vadalog cattura ed estende Datalog senza aumentare tale complessità, questo avviene grazie alle proprietà ereditate dal frammento di Datalog$^\pm$ (Warded Datalog$^\pm$ in particolare) su cui si basa. In termini intuitivi, il Warded Datalog$^\pm$ (così come altri frammenti di Datalog$^\pm$) contiene la propagazione dei valori nulli nell'ambito della ricorsione. Il linguaggio riesce ad imporre tali vincoli grazie a semplici restrizioni sintattiche, che individuano quali variabili possono contenere valori nulli che si propagano nella testa (variabili \emph{dangerous}), e impongono che tali variabili debbano sempre comparire esattamente in un atomo del corpo (detto \emph{ward}) che interagisce con gli altri atomi del corpo solo mediante variabili che non possono assumere valori nulli (\emph{harmless})~\cite{bellomarini2017swift}. \newline
Il Vadalog Reasoner fornisce anche degli strumenti che permettono la gestione di analytics, l'iniezione di codice procedurale, l'integrazione con diverse tipologie di input (ad esempio database relazionali, file csv, database non relazionali, ecc.).\newline \newline
Il mio contributo in questa tesi è stato l'implementazione di feature core del Vadalog Reasoner per l'esecuzione di programmi Vadalog. Inizialmente il progetto presentava un ambito di intervento molto vasto: 
\begin{itemize}
	\item Non erano presenti diversi tipi di dati, anche primitivi, per permettere all'utente di effettuare maggiori statistiche. Tale requisito è fondamentale se si vogliono integrare tipi di dati nel linguaggio Vadalog.
	\item Non erano presenti delle ottimizzazioni per permettere un guadagno sull'esecuzione di programmi Vadalog. Ciò rappresentava un limite volendo guadagnare in efficienza e permettere quindi delle performance migliori. Ad esempio non veniva ottimizzata efficientemente la ricorsione. 
	\item Erano stati effettuati soltanto dei benchmark iniziali per testare le perfomance, ma nulla di concreto per effettuare anche confronti con i competitor esistenti, e quindi capire se il sistema fosse competitivo nel settore.
	\item Le sorgenti a disposizione dell'utente finale erano in numero limitato. Anche questo problema rappresentava un collo di bottiglia per il nostro sistema, in quanto l'utente aveva poche sorgenti per incrociare i dati ed effettuarne analisi. 
	\item Non era possibile integrare codice sorgente da altri linguaggi, né definire funzioni all'interno del linguaggio Vadalog. Ciò era un limite, poiché non permetteva di fare computazioni laboriose o di utilizzare del codice già scritto in precedenza (magari dedicato ad un calcolo ben definito).
	\item Era presente un'interfaccia web molto scarna e con poche funzionalità. L'utente aveva accesso soltanto a poche funzionalità rispetto a tutte le funzionalità fornite dal sistema.
\end{itemize}
Di seguito una breve lista delle funzionalità di cui mi sono occupato, che verranno illustrate in maniera più approfondita nei prossimi capitoli:
\begin{itemize}
	\item Implementazione di nuovi tipi di dato, semplici e strutturati, per risolvere il problema dei pochi tipi di dato disponibili nel sistema.
	\item Tecniche di ottimizzazione in Datalog per migliorare le prestazioni. In particolare mi sono occupato delle ottimizzazioni di: \emph{Push Selections e Projections Down}, ovvero la trasformazione di una query in un'altra equivalente, ma anticipando le selezioni e le proiezioni alle regole più vicine a quelle di input (ad esempio l'ideale sarebbe inserire le selezioni e le proiezioni alle regole di input), questo risulta efficiente poiché coinvolge un numero minore di tuple nell'operazione di join~\cite{atzeni2006basi}; supporto per ricorsione sinistra e destra, trasformazione dove le ricorsioni destre (nel corpo di una regola l'atomo che ricorre si trova alla destra di tutti gli altri atomi) che risultano più problematiche anche a livello di computazione temporale, vengono opportunamente trasformate in ricorsioni sinistre (nel corpo di una regola l'atomo che ricorre si trova alla sinistra di tutti gli altri atomi) che risultano più efficienti; ottimizzazione multi-join, ovvero quando si è in presenza di regole che hanno al loro interno join condivisi tra tre o più atomi, essi vengono splittati in un numero di regole proporzionale al numero di atomi, in modo di avere al più regole con un join tra due atomi.
	\item Creazione di benchmark per effettuare test sulle performance per effettuare analisi esaustive sulle performance del sistema ed effettuare infine confronti con altri sistemi esistenti. Mi sono occupato inoltre dello sviluppo di \textit{iWarded}, un piccolo tool che genera programmi Warded Datalog$^\pm $ per effettuare benchmark. Tale sistema prende in input diversi parametri che hanno lo scopo di descrivere le particolarità del programma Vadalog, e ne restituisce quest'ultimo.
	\item Supporto di nuove sorgenti, file CSV e database relazionali e non relazionali. Questo permette maggiore interazione per l'utente, è così possibile combinare i dati provenienti da storage eterogenei ed effettuare statistiche e tutte le operazioni offerte dal sistema su di essi.
	\item Supporto alle user-defined functions. È possibile definire delle funzioni all'interno di Vadalog, al quale è possibile passare dei parametri, ed è possibile esprimere la correlazione tra esse e funzioni esterne che possono essere implementate in diversi linguaggi. Essenziali per l'utente se vuole integrare funzioni all'interno del programma Vadalog, ad esempio funzioni già scritte in passato che calcolano una determinata statistica.
	\item Miglioramento notevole dell'interfaccia web (Vadalog console), con l'integrazione di elementi grafici che permettono l'interazione con tutti i servizi offerti dal sistema, integrazione di un editor e tante altre funzionalità. \newline
\end{itemize} 
La tesi è organizzata come segue: \newline \newline
Il capitolo 1 descrive il Vadalog Engine, in particolare le proprietà di un KGMS ed in modo approfondito l'architettura del nostro sistema. \newline \newline
Il capitolo 2 è incentrato sul linguaggio Vadalog, in particolare è presente un approfondimento più ampio sul core logico della famiglia di linguaggi Datalog$^\pm$ e di Vadalog, della complessità e delle estensioni di quest'ultimo. \newline \newline
Il capitolo 3 è dedicato alla descrizione nel dettaglio delle funzionalità riguardanti il mio contributo al progetto. \newline \newline
Il capitolo 4 descrive le prove sperimentali effettuate sul sistema Vadalog. \newline \newline
Il capitolo 5 confronta il sistema Vadalog con i competitor già presenti sul mercato. \newline \newline
Il capitolo 6 trae le conclusioni del lavoro.
